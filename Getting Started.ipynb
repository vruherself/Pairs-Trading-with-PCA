{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "registered-masters",
   "metadata": {},
   "source": [
    "### The goal is to get the outline, plan of attack for the implemetation of the paper and test some improvements.\n",
    "    - pick a sector\n",
    "    - scrape the web to get the top 300 / 500 / 800 stocks and their trade symbols from yfinance.\n",
    "    - make a dataframe of the returns for the stocks that you have downloaded.\n",
    "    - picking the pairs can happen in the permutation of the following:\n",
    "        - (GARCH or not) clustering of the time series data\n",
    "        - Double stage correlation and cointegration\n",
    "        - vanilla cointegration\n",
    "    - do PCA on the sector indices and construct the eigen portfolio form the eigenvalues.\n",
    "    - model the parameters of the residual as orienstein uhlenbeck process using the sde package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-trinidad",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pregnant-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-continent",
   "metadata": {},
   "source": [
    "### The sector I am working with here as an experimentation is pharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offshore-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-mystery",
   "metadata": {},
   "source": [
    "Getting the url's of the pages which contains the data for n stocks from pharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "musical-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=0\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=25\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=50\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=75\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=100\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=125\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=150\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=175\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=200\n",
      "https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=225\n"
     ]
    }
   ],
   "source": [
    "l=np.arange(0,226,25)\n",
    "for i in range(len(l)):\n",
    "    url = 'https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=' + str(l[i])\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exterior-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_webpages = []\n",
    "for i in range(len(l)):\n",
    "    url = 'https://finance.yahoo.com/screener/unsaved/bc105bad-a0a2-4e16-bd3e-884c0b2771ad?count=25&dependentField=sector&dependentValues=Healthcare&offset=' + str(l[i])\n",
    "    list_webpages.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-bishop",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-719e533ea2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_webpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_webpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Symbol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "symbol = pd.Series([1])\n",
    "for i in range(len(list_webpages)):\n",
    "    df_list = pd.read_html(list_webpages[i])\n",
    "    symbol = pd.concat([symbol, df_list[0][\"Symbol\"]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = pd.DataFrame(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = symbol.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = symbol.rename(columns={0: \"Symbol\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-surgery",
   "metadata": {},
   "source": [
    "### Get the Adj close price for all the symbols listed in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = yf.download(['DIVISLAB.NS', 'DRREDDY.BO'], '2018-01-01', '2019-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-breakfast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbol[\"Symbol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-elimination",
   "metadata": {},
   "source": [
    "#### Separating the stocks form NSE exchange and BSE exchange\n",
    "Some of the stocks in the dataframe are repeated as the same stock sold on NSE and BSE are counted as "
   ]
  },
  {
   "cell_type": "raw",
   "id": "linear-monaco",
   "metadata": {},
   "source": [
    "NS=[]\n",
    "BO=[]\n",
    "for i in range(1,len(symbol)):\n",
    "    l = symbol[\"Symbol\"][i].split('.')\n",
    "    if l[1] == 'NS':\n",
    "        NS.append(symbol[\"Symbol\"][i])\n",
    "    else:\n",
    "        BO.append(symbol[\"Symbol\"][i])   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "trained-southeast",
   "metadata": {},
   "source": [
    "Unique = []\n",
    "for i in range(1, len(symbol)):\n",
    "    l = symbol[\"Symbol\"][i].split('.')\n",
    "    for j in range(i, len(symbol)):\n",
    "        k = symbol[\"Symbol\"][j].split('.')\n",
    "    if l[0] != k[0]:\n",
    "            Unique.append(symbol[\"Symbol\"][i])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "catholic-soundtrack",
   "metadata": {},
   "source": [
    "u = symbol[\"Symbol\"]\n",
    "op=[]\n",
    "for i in range(1, len(symbol)):\n",
    "    l = symbol[\"Symbol\"][i].split('.')\n",
    "    for j in range(i+1, len(symbol)):\n",
    "        k = symbol[\"Symbol\"][j].split('.')\n",
    "    if l[0] != k[0]:\n",
    "            op.append(l[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-basics",
   "metadata": {},
   "source": [
    "The following method works to get a unique list of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [1]\n",
    "for i in range(1,len(symbol)):\n",
    "    l= symbol[\"Symbol\"][i].split('.')\n",
    "    r.append(l[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = symbol[\"Symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r)):\n",
    "    for j in range(i+1, len(r)):\n",
    "        if r[i] == r[j]:\n",
    "            dup = dup.drop(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup1 = dup.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dup1[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-image",
   "metadata": {},
   "source": [
    "Phewww!! finally I now have a dataframe with proper indexing and no repeating stocks. Now I need to save this as a csv file to be recalled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup1.to_csv(\"Pharma Stock Symbols from NSE and BSE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_symbols = []\n",
    "for i in range(len(dup1)):\n",
    "    list_of_symbols.append(dup1[\"Symbol\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = yf.download(list_of_symbols, '2018-01-01', '2019-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.to_csv(\"Pharma Stock - All Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "close = stock_data[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "del close['GLAND.NS']\n",
    "del close['SUVENPHAR.NS']\n",
    "del close['NOVARTIND.NS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in close.columns:\n",
    "    if (close[cols].isna().sum() >0):\n",
    "        del close[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-brooklyn",
   "metadata": {},
   "source": [
    "saving the dataframe with adjusted close prices and all the NaN values droped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "close.to_csv('Adj_Close.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = close.pct_change(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = returns.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-manufacturer",
   "metadata": {},
   "source": [
    "# Finding Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-brook",
   "metadata": {},
   "source": [
    "## Finding pairs using the clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns that you are goin gto use for clustering :- volume and returns\n",
    "\n",
    "metrics = [\"Volume\", \"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data1 = stock_data[metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data1.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data1 = stock_data1.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data1.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns =  stock_data1[\"Adj Close\"].pct_change(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns =returns.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([stock_data1, returns], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-hours",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components', fontsize = 15)\n",
    "plt.ylabel('Variance (%)', fontsize = 15) \n",
    "plt.title('Explained Variance', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "results_dict = {}\n",
    "num_of_clusters = 10\n",
    "\n",
    "\n",
    "for k in range(2, num_of_clusters):\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # define the next dictionary to hold all the results of this run.\n",
    "    results_dict[k] = {}\n",
    "\n",
    "    # create an instance of the model, and fit the training data to it.\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(returns)\n",
    "    \n",
    "    # define the silhouette score\n",
    "    sil_score = metrics.silhouette_score(returns, kmeans.labels_, metric='euclidean')\n",
    "    \n",
    "    # store the different metrics\n",
    "    results_dict[k]['silhouette_score'] = sil_score\n",
    "    results_dict[k]['inertia'] = kmeans.inertia_\n",
    "    results_dict[k]['score'] = kmeans.score\n",
    "    results_dict[k]['model'] = kmeans\n",
    "    \n",
    "    # print the results    \n",
    "    print(\"Number of Clusters: {}\".format(k))\n",
    "    print('Silhouette Score:', sil_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-mixer",
   "metadata": {},
   "source": [
    "## Finding pairs using the double stage cointegration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-engineer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-quebec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-cameroon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-seating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-evening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-consensus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-architect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-battlefield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-pickup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outside-exploration",
   "metadata": {},
   "source": [
    "## Find pairs using simply the cointegration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-celebrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-chinese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-hunter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-injection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-voice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-exclusive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-distinction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
